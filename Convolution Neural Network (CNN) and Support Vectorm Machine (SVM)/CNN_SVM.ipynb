{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brandon L Morrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Neural Network \n",
    "We will use a built-in Convolutional Neural Network (CNN) using either the MNIST data sets and show the classification accuracy:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input shapes:\n",
      "x_train shape: (60000, 28, 28)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n",
      "\n",
      "Updated shapes:\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c4780afc70>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I was forced to update tensorflow in environment to use on CNN\n",
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Lets confirm the shapes are what we want them to be\n",
    "print(f\"\\nInput shapes:\")\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Lets reshape the data to be 4 dimensional to match layer input size for our CNN\n",
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)\n",
    "\n",
    "# Lets confirm the shapes are what we want them to be\n",
    "print(f\"\\nUpdated shapes:\")\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Now lets look at the first image to confirm data properly loaded\n",
    "fig = plt.figure(figsize=(1,1)) # Shrinks the image\n",
    "plt.axis('off') \n",
    "plt.imshow(x_train[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not utilizing GPU\n",
      "Training may take a long time without using GPU\n",
      "\n",
      "Available devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU support\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Tensorflow not utilizing GPU\")\n",
    "    print(\"Training may take a long time without using GPU\")\n",
    "\n",
    "# Show available devices\n",
    "devices = tf.config.list_physical_devices()\n",
    "print(f\"\\nAvailable devices:\\n{devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets start to build the neural network\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train[0]  # Lets confirm the number is a 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "# Create model\n",
    "model = Sequential()\n",
    "\n",
    "# Add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1))) # 2D convolutional layer with 64 filters\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu')) # Second layer with 32 filters\n",
    "model.add(Flatten()) # Turns previous layer into one dimension for the next dense layer\n",
    "model.add(Dense(10, activation='softmax')) # Adds dense layer with 10 outputs for 10 digits. Softmax converts to probabilities\n",
    "\n",
    "# Compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 47s 25ms/step - loss: 0.2571 - accuracy: 0.9534 - val_loss: 0.0883 - val_accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c4780af970>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/fit the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=1) # Would do more than 1 epoch but takes too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step\n",
      "[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 5 4 9 6 6 5 4 0 7 4 0 1]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1]\n",
      "Test set accuracy: 97.2 %\n"
     ]
    }
   ],
   "source": [
    "# Lets predict the test set\n",
    "predicted = model.predict(x_test)\n",
    "actual = y_test\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "predicted_indices = np.argmax(predicted, axis=1)\n",
    "actual_indices = np.argmax(actual, axis=1)\n",
    "\n",
    "# Lets compare the first 30 predictions to the actual values\n",
    "print(predicted_indices[:30])\n",
    "print(actual_indices[:30]) \n",
    "\n",
    "# Calculate accuracy as the fraction of correct predictions\n",
    "accuracy = np.mean(predicted_indices == actual_indices)\n",
    "\n",
    "# print the accuracy\n",
    "print('Test set accuracy:', accuracy * 100, '%')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we would expect we see that the predictions line up well with the test data on first 30 values. Lets be safe double check our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted = [7. 2. 1. 0. 4.]\n",
      "actual = [7. 2. 1. 0. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Now lets double check the first five numbers match their actual pictures\n",
    "predicted_values = np.zeros(5)\n",
    "actual_values = np.zeros(5)\n",
    "for i in range(5):\n",
    "    predicted_values[i] = np.argmax(predicted[i])\n",
    "    actual_values[i] = np.argmax(actual[i])\n",
    "print(f\"predicted = {predicted_values}\")\n",
    "print(f\"actual = {actual_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now lets plot the first 5 images in the test set to confirm the predictions\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(5, 2))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(x_test[i], cmap=\"gray\")\n",
    "    ax.set_title(f\"Image: {i}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We can see that our predicted and actual values line up with what we would expect to see from the model. We also saw a test accuracy of  97.59% Which is to be expected for our neural network, and confirming the first values appears that the implementation of the CNN is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pseudocode for an SVM classifier using a linear and separately an rbf kernel.<br><br>\n",
    "2. Analyzes the runtime of your design in big O notation and calculate a total runtime such that each line of psuedocode is accounted for.<br><br>\n",
    "3. Implementation of SVM using Python:<br><br>\n",
    "    - Train three two class models using the Iris dataset as input training data, the Iris data will need to be reconfigured as a one vs. all or one vs. one data set.\n",
    "    - Process the test data set to determine which class each test observation belongs to, in this problem you will simply use all 150 observations as your test data.\n",
    "    - What is the classification accuracy?\n",
    "    - Is there a difference in performance between the two kernels? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Psuedocode #\n",
    "\n",
    "Import libraries\n",
    "\n",
    "Import iris\n",
    "\n",
    "## function linear_kernel(x1, x2):<b> \n",
    "    return np.dot(x1, x2)\n",
    "\n",
    "## function rbf_kernel(x1, x2, gamma): \n",
    "    distance = np.linalg.norm(x1 - x2) ** 2\n",
    "    return np.exp(-gamma * distance)\n",
    "\n",
    "## function train_SVM(x, x, options):\n",
    "\n",
    "    kernel_name, arg, c = options['kernel'], options['arg'], options['c']\n",
    "    mu = 1e-12\n",
    "    num_data = x.shape\n",
    "    \n",
    "    K = kernel_SVM(x, x, kernel_name, arg)\n",
    "    \n",
    "    H = np.multiply(K, np.outer(y, y))\n",
    "    H = H + (mu * np.eye(H.shape[0]))\n",
    "        \n",
    "    # Now set up the optimization problem\n",
    "    P = cvxopt.matrix(P, tc='d')\n",
    "    q = cvxopt.matrix(q, tc='d')\n",
    "    G = cvxopt.matrix(G, tc='d')\n",
    "    h = cvxopt.matrix(h, tc='d')\n",
    "    A = cvxopt.matrix(A, tc='d')\n",
    "    b = cvxopt.matrix(b, tc='d')\n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    \n",
    "    alpha = sol['x']\n",
    "    epsi = 1e-12 \n",
    "    \n",
    "    # Now lets get the support and boundary vector boundaries\n",
    "    sv_inx = where(alpha > epsi)\n",
    "    boundary_inx = get boundary index locaiton\n",
    "    dec_boundary = decision boundary formula # Confirmed with matlab\n",
    "\n",
    "    prediction = K @ alpha + dec_boundary \n",
    "    temp = np.ones(num_data)\n",
    "    temp[np.where(prediction < 0)] = -1 # set all values less than 0 to -1\n",
    "    err = np.sum(np.abs(temp - y)) / num_data * 100\n",
    "\n",
    "    model = {\n",
    "        'alpha': alpha[sv_inx],\n",
    "        'dec_boundary': dec_boundary,\n",
    "        'options': options,\n",
    "        'svX': x[sv_inx, :],\n",
    "        'err': err,\n",
    "        'sv_y': y[sv_inx],\n",
    "        'sv_indx': np.where(sv_inx)[0],\n",
    "        'numberSV': np.sum(sv_inx)\n",
    "    }\n",
    "\n",
    "    return model\n",
    "\n",
    "## function classify_SVM(x, model):\n",
    "\n",
    "    extract values from model\n",
    "    K = kernel_SVM(x, svX, kernel, arg)\n",
    "    prediction = np.dot(K, alpha) + dec_boundary\n",
    "    return prediction\n",
    "\n",
    "\n",
    "## functions SVM(kernel_name, arg, c):    \n",
    "\n",
    "    # Add inputs to list options\n",
    "    kernel_name, arg, c = options['kernel'], options['arg'], options['c']\n",
    "\n",
    "    setosa = iris.data.toNumpy(replace setosa = 1, replace versicolor = -1, replace virginica = -1)\n",
    "    versicolor = iris.data.toNumpy(replace setosa = -1, replace versicolor = 1, replace virginica = -1)\n",
    "    virginica = iris.data.toNumpy(replace setosa = -1, replace versicolor = -1, replace virginica = 1)\n",
    "    \n",
    "    iris_y = setosa + versicolor + virginica\n",
    "    iris_x = iris[features]\n",
    "\n",
    "    # Train the models\n",
    "    model1 = train_SVM(dataX, setosa_y, options)\n",
    "    model2 = train_SVM(dataX, versicolor_y, options)\n",
    "    model3 = train_SVM(dataX, virginica_y, options)\n",
    "\n",
    "    # Now classify using the trained models\n",
    "    ypred1 = rbf_classify(iris_x, model1)\n",
    "    ypred2 = rbf_classify(iris_x, model2)\n",
    "    ypred3 = rbf_classify(iris_x, model3)\n",
    "    predictions = ypred1 + ypred2 + ypred3\n",
    "\n",
    "    # Combine the predictions and calculate the accuracy\n",
    "    tmp = pred_setosa + pred_versicolor + pred_virginica\n",
    "    pred_classes = np.argmax(tmp)\n",
    "    \n",
    "    true_classes = iris_df.iloc[:, -1].replace({'setosa': 0, 'versicolor': 1, 'virginica': 2}).values\n",
    "    accuracy = sum(pred_classes == true_classes) / len(true_classes) * 100\n",
    "    misclassified = np.where(true_classes != pred_classes) # get indexes of misclassifications\n",
    "\n",
    "    print(Kernel: {kernel_name})\n",
    "    print(Arg: {arg})\n",
    "    print(C: {c})\n",
    "    print(Classification accuracy: {accuracy}%)\n",
    "    print(Misclassified: {len(misclassified)})\n",
    "    print(Misclassified Indices: {misclassified})\n",
    "    print(Predicted valuess: {pred_classes})\n",
    "    print(Actual Values: {true_classes})\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 O(n) Analysis: ##\n",
    "The time complexity of the algorithm should be mostly impacted by the effect of the nested for loops to calculate the kernel functions this function brings the complexity to O(n^2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cvxopt\n",
    "\n",
    "# This will define the different kernel functions\n",
    "def kernel(x1, x2, kernel_name, arg):\n",
    "    if kernel_name == 'linear': # Linear kernel\n",
    "        k = x1.T @ x2\n",
    "    elif kernel_name == 'rbf': # Radial Basis Function kernel\n",
    "        squared_diff = np.sum((x1 - x2) ** 2)\n",
    "        k = np.exp(-0.5 * squared_diff / (arg ** 2))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid kernel type '{kernel_name}'\")\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validated\n",
    "# This will choose the correct kernel function to use\n",
    "def kernel_SVM(x1, x2, kernel_name, arg):\n",
    "    row1 = x1.shape[0]\n",
    "    row2 = x2.shape[0] \n",
    "    k = np.zeros((row1, row2))\n",
    "    for i in range(row1):\n",
    "        for j in range(row2):\n",
    "            k[i, j] = kernel(x1[i, :], x2[j, :], kernel_name, arg)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will train the SVM\n",
    "def train_SVM(x, y, options):\n",
    "\n",
    "    kernel_name, arg, c = options['kernel'], options['arg'], options['c']\n",
    "    mu = 1e-7 # Compensates for floating point errors\n",
    "    num_data = x.shape[0]\n",
    "    \n",
    "    K = kernel_SVM(x, x, kernel_name, arg)\n",
    "    \n",
    "    H = np.multiply(K, np.outer(y, y))\n",
    "    H = H + (mu * np.eye(H.shape[0]))\n",
    "        \n",
    "    # Now set up the optimization problem\n",
    "    P = np.outer(y,y) * H\n",
    "    q = -np.ones(num_data)\n",
    "    G = np.vstack([-np.eye(num_data), np.eye(num_data)])\n",
    "    h = np.hstack([np.zeros(num_data), c*np.ones(num_data)])\n",
    "    A = y.reshape(1,-1)\n",
    "    b = np.array([0.])\n",
    "    # print(f\"\\nP Shape: {P.shape}\")\n",
    "    # print(f\"q Shape: {q.shape}\")\n",
    "    # print(f\"G Shape: {G.shape}\")\n",
    "    # print(f\"h Shape: {h.shape}\")\n",
    "    # print(f\"A Shape: {A.shape}\")\n",
    "    # print(f\"b Shape: {b.shape}\")\n",
    "    \n",
    "    P = cvxopt.matrix(P, tc='d')\n",
    "    q = cvxopt.matrix(q, tc='d')\n",
    "    G = cvxopt.matrix(G, tc='d')\n",
    "    h = cvxopt.matrix(h, tc='d')\n",
    "    A = cvxopt.matrix(A, tc='d')\n",
    "    b = cvxopt.matrix(b, tc='d')\n",
    "    cvxopt.solvers.options['show_progress'] = False\n",
    "    sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    \n",
    "    alpha = np.array(sol['x']).flatten() # Output validated with matlab    \n",
    "    epsi = 1e-7  # This is to compensate for float point arithmatic \n",
    "    \n",
    "    # Now lets get the support and boundary vector boundaries\n",
    "    sv_inx = np.where(alpha > epsi)[0]  \n",
    "    boundary_inx = np.where(((c - epsi) > alpha) & (alpha > epsi))[0]\n",
    "\n",
    "    if len(boundary_inx) > 0:\n",
    "        dec_boundary = np.sum(y[boundary_inx] - (H[boundary_inx][:, sv_inx] @ (alpha[sv_inx] * y[sv_inx]))) / len(boundary_inx) \n",
    "    else:\n",
    "        dec_boundary = 0\n",
    "    \n",
    "    prediction = K @ alpha + dec_boundary \n",
    "    temp = np.ones(num_data)\n",
    "    temp[np.where(prediction < 0)] = -1 # set all values less than 0 to -1\n",
    "    err = np.sum(np.abs(temp - y)) / num_data * 100\n",
    "    \n",
    "    model = {\n",
    "        'alpha': alpha[sv_inx],\n",
    "        'dec_boundary': dec_boundary,\n",
    "        'options': options,\n",
    "        'svX': x[sv_inx, :],\n",
    "        'err': err,\n",
    "        'sv_y': y[sv_inx],\n",
    "        'sv_indx': np.where(sv_inx)[0],\n",
    "        'numberSV': np.sum(sv_inx)\n",
    "    }\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_SVM(x, model):\n",
    "    alpha = model['alpha']\n",
    "    dec_boundary = model['dec_boundary']\n",
    "    svX = model['svX']\n",
    "    kernel = model['options']['kernel']\n",
    "    arg = model['options']['arg']\n",
    "\n",
    "    K = kernel_SVM(x, svX, kernel, arg)\n",
    "    prediction = np.dot(K, alpha) + dec_boundary\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type the code for part 3 here ##\n",
    "\n",
    "# We will implement an SVM classifier from scratch. This classifier will be one vs all\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "def SVM(kernel_name, arg, c, n_splits=5):\n",
    "    \n",
    "    iris_df = pd.read_csv(\"iris.csv\")\n",
    "    options = {'kernel': kernel_name, 'arg': arg, 'c': c}\n",
    "\n",
    "    # Now create one vs all arrays that are [150,]\n",
    "    iris_setosa_y = iris_df.iloc[:, -1].replace({'setosa': 1, 'versicolor': -1, 'virginica': -1}).values\n",
    "    iris_versicolor_y = iris_df.iloc[:, -1].replace({'setosa': -1, 'versicolor': 1, 'virginica': -1}).values\n",
    "    iris_virginica_y = iris_df.iloc[:, -1].replace({'setosa': -1, 'versicolor': -1, 'virginica': 1}).values    \n",
    "    iris_x = iris_df.iloc[:, 2:4].values # Will be [150 x 2] to match the matlab code\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    iris_x = scaler.fit_transform(iris_x) # Standardize the data\n",
    "    \n",
    "    # Train the models\n",
    "    model1 = train_SVM(iris_x, iris_setosa_y, options)\n",
    "    model2 = train_SVM(iris_x, iris_versicolor_y, options)\n",
    "    model3 = train_SVM(iris_x, iris_virginica_y, options)\n",
    "\n",
    "    # Classify the data using the trained models\n",
    "    pred_setosa = classify_SVM(iris_x, model1)\n",
    "    pred_versicolor = classify_SVM(iris_x, model2)\n",
    "    pred_virginica = classify_SVM(iris_x, model3)\n",
    "\n",
    "    # Combine the predictions and calculate the accuracy\n",
    "    tmp = np.vstack((pred_setosa, pred_versicolor, pred_virginica)).T\n",
    "    pred_classes = np.argmax(tmp, axis=1)\n",
    "    \n",
    "    true_classes = iris_df.iloc[:, -1].replace({'setosa': 0, 'versicolor': 1, 'virginica': 2}).values\n",
    "    accuracy = (np.sum(pred_classes == true_classes) / len(true_classes)) * 100\n",
    "    misclassified = np.where(true_classes != pred_classes)[0] # get indexes of misclassifications\n",
    "\n",
    "    print(f'\\nKernel:{kernel_name} Arg:{arg} C:{c}')\n",
    "    print(f'Classification accuracy: {accuracy}%\\n')\n",
    "    print(f'Misclassified Indices: {misclassified}')\n",
    "    print(f'Total Misclassified: {len(misclassified)}\\n')\n",
    "    #print(f'Predicted values:\\n{pred_classes}\\n')\n",
    "    #print(f'Actual Values:\\n{true_classes}\\n')\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets first look at and evaluate the regularization constant C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel:rbf Arg:0.015 C:1\n",
      "Classification accuracy: 74.0%\n",
      "\n",
      "Misclassified Indices: [ 5 12 13 16 18 19 20 22 23 24 26 43 44 54 55 56 58 59 61 62 64 67 69 70\n",
      " 73 76 77 80 81 82 83 85 86 87 90 91 92 95 98]\n",
      "Total Misclassified: 39\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Kernel:rbf Arg:0.015 C:10\n",
      "Classification accuracy: 98.66666666666667%\n",
      "\n",
      "Misclassified Indices: [126 138]\n",
      "Total Misclassified: 2\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Kernel:rbf Arg:0.015 C:100\n",
      "Classification accuracy: 99.33333333333333%\n",
      "\n",
      "Misclassified Indices: [70]\n",
      "Total Misclassified: 1\n",
      "\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# We will first test RBF kernel with different values of C\n",
    "c_values = [1, 10, 100]\n",
    "# Loop through the C values and test each one\n",
    "for c in c_values:\n",
    "    SVM(\"rbf\", arg=.015, c=c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> RBF Kernel Regularization Constant (C) Analysis:\n",
    "\n",
    "As expected we see that the accuracy increases when C is increased for our RBF kernel.\n",
    "\n",
    "We see that as we increase C the harder the margin becomes and the less crossover is allowed. If we leave gamma the same we see that increasing c \"hardens\" the margin and increases classification accuracy, but at the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel:linear Arg:None C:1\n",
      "Classification accuracy: 86.0%\n",
      "\n",
      "Misclassified Indices: [ 59  61  64  70  85 103 105 107 108 116 117 118 119 122 125 129 130 131\n",
      " 133 134 137]\n",
      "Total Misclassified: 21\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Kernel:linear Arg:None C:10\n",
      "Classification accuracy: 86.66666666666667%\n",
      "\n",
      "Misclassified Indices: [ 59  61  70  85 103 105 107 108 116 117 118 119 122 125 129 130 131 133\n",
      " 134 137]\n",
      "Total Misclassified: 20\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Kernel:linear Arg:None C:100\n",
      "Classification accuracy: 88.66666666666667%\n",
      "\n",
      "Misclassified Indices: [ 70 103 105 107 108 116 117 118 119 122 125 129 130 131 133 134 137]\n",
      "Total Misclassified: 17\n",
      "\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Now lets look at the linear kernel with different values of C\n",
    "c_values = [1, 10, 100]\n",
    "# Loop through the C values and test each one\n",
    "for c in c_values:\n",
    "    SVM(\"linear\", arg=None, c=c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Linear Kernel Regularization Constant (C) Analysis:\n",
    "\n",
    "As expected again we see that misclassifications are minimized as we increase our regularization constant. Larger C values minimize misclassifications for both the linear and RBF kernels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets look at adjusting gamma for RBF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel:rbf Arg:0.01 C:3\n",
      "Classification accuracy: 99.33333333333333%\n",
      "\n",
      "Misclassified Indices: [70]\n",
      "Total Misclassified: 1\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Kernel:rbf Arg:0.1 C:3\n",
      "Classification accuracy: 98.0%\n",
      "\n",
      "Misclassified Indices: [ 54 126 138]\n",
      "Total Misclassified: 3\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Kernel:rbf Arg:1 C:3\n",
      "Classification accuracy: 94.0%\n",
      "\n",
      "Misclassified Indices: [52 56 70 72 76 77 83 85 86]\n",
      "Total Misclassified: 9\n",
      "\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "arg_values = [.01, .1, 1]\n",
    "# Loop through the C values and test each one\n",
    "for arg in arg_values:\n",
    "    SVM(\"rbf\", arg=arg, c=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> RBG Gamma (arg) Analysis:\n",
    "\n",
    "With gamma low we see that the rbf creates smoother decision boundaries and allows for the model to generalize the classes well.\n",
    "\n",
    "As we increase the gamma we see that the decision boundary becomes more complex, and we begin to see issues that are cause by overfitting of our decision boundary. This causes a decrease in the classification accuracy from overfitting.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Linear vs RBF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We see that generally the linear and RBF kernels are both effective classifiers. The difference between the two kernels is that the RBF kernel allows for fitting to models that are not linearly seperable. The RBF function has the additional gamma hyperparamater that controls the rbf shape. This additional hyperparamater allows for the model to be more closely fitted to the data. The RBF beats out the linear classfier on accuracy in most cases with correctly chosen hyperparamaters. A drawback is the RBF function is much easier to accidently overfit if one does not correctly tune the gamma parameter. \n",
    "\n",
    "If the data were clearly linearly seperable it is even possible for the linear kernel to see better performance than the RBF kernel. Although this is not as likely for closely related data. The linear kernel is also less prone to overfitting since it constructs a simple hyperplane. This type of kernel benefits from its simplicity and by being less prone to overfitting. Plotting the data for the two features we are evaluating we see that the versicolor and virginica have a lot of overlapping sections, which is why the RBF functino returns a greater accuracy than the linear kernal(graph below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris_df = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "#sns.scatterplot(x=iris_df.iloc[:, 2], y=iris_df.iloc[:, 3], hue=iris_df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References<br><br>\n",
    "[1] Charu C. Aggarwal, Neural Networks and Deep Learning, Springer 2018<br><br>\n",
    "[2] Ahmad Abdolsaheb, How to make your Tic Tac Toe game unbeatable by using the minimax algorithm,\n",
    "2020, https://www.freecodecamp.org/news/how-to-make-your-tic-tac-toe-game-unbeatable-byusing-\n",
    "the-minimax-algorithm-9d690bad4b37/<br><br>\n",
    "[3] Francois Chollet, Deep Learning with Python, Manning, 2018<br><br>\n",
    "[4] Stephen Cook, The Complexity of Theorem Proving Procedures, Proceedings of the third annual ACM symposium<br><br>\n",
    "on Theory of computing, pp. 151-158, 1971\n",
    "[5] Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning, MIT Press, 2016,\n",
    "https://www.deeplearningbook.org/<br><br>\n",
    "[6] Patric Honner (Contributing Columnist), Why Winning in Rock-Paper-Scissors (and in Life) Isnt Everything,\n",
    "What does John Nashs game theory equilibrium concept look like in Rock-Paper-Scissors?, an article in the\n",
    "online Quanta Magazine, April 2, 2018, https://www.quantamagazine.org/the-game-theory-math-behindrock-\n",
    "paper-scissors-20180402/<br><br>\n",
    "[7] Richard M. Karp, Reducibility Among Combinatorial Problems, In R. E. Miller and J. W. Thatcher (editors),\n",
    "Complexity of Computer Computations, New York: Plenum, pp. 85-103, 1972<br><br>\n",
    "[8] Stephen G. Nash and Ariela Sofer, Linear and Nonlinear Programming, McGraw-Hill, 1996<br><br>\n",
    "[9] Stuart Russell and Peter Norvig, Articial Intelligence a Modern Approach Fourth Edition, Pearson, 2020<br><br>\n",
    "[10] Sergios Theodoridis and Konstantinos Koutroumbas, Pattern Recognition Third Edition, San Diego, CA:\n",
    "Academic Press, 2006<br><br>\n",
    "[11] Thomas H. Cormen, Charles E. Leiserson, Ronal L. Rivest and Cliord Stein, Introduction to Algorithms,\n",
    "3rd Edition, MIT Press, 2009<br><br>\n",
    "[12] David Zuckerman, NP-Complete Problems Have a Version Thats Hard to Approximate, IEEE, Proceedings\n",
    "of the Eighth Annual Structure in Complexity Theory Conference, pp. 305-312, 1993<br><br>\n",
    "[13] David Zuckerman, On Unapproximable Versions of NP-Complete Problems, SIAM Journal on Computing,\n",
    "Volume 25, Issue 6, pp. 1293-1304, 1996"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
